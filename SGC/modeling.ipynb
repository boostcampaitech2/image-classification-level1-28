{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f9e247e-57d6-4298-8c53-63008859eef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install albumentations==0.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9487d06-e224-4934-8115-4ea7590b7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ed7b70-957b-4e7b-83da-4ad6eddc6195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is using!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device} is using!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c712ae0-040f-415c-9136-bba217534602",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 8\n",
    "OUTPUT_CLASS = 18\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6444cae5-f5a9-4f13-a9d9-5b5b5d91e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path, label, transform):\n",
    "        img_list = []\n",
    "        for p in tqdm(path):\n",
    "            img = cv2.imread(p)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_list.append(img)\n",
    "        \n",
    "        self.X = img_list\n",
    "        self.y = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        len_dataset = len(self.X)\n",
    "        return len_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X,y = self.X[idx], self.y[idx]\n",
    "        X = self.transform(image=X)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d79a793c-166a-4cd6-8ae3-cc8b542f2104",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, path, label, transform):\n",
    "        img_list = []\n",
    "        for p in tqdm(path):\n",
    "            img = cv2.imread(p)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_list.append(img)\n",
    "        \n",
    "        self.X = img_list\n",
    "        self.y = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        len_dataset = len(self.X)\n",
    "        return len_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X,y = self.X[idx], self.y[idx]\n",
    "        X = self.transform(image=X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8891d3eb-7b2b-4a85-a667-b2cb2ffe8fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = albumentations.Compose(\n",
    "  [\n",
    "      albumentations.Resize(600,600),\n",
    "#       albumentations.RandomRotation(15),\n",
    "      albumentations.HorizontalFlip(p=0.3),\n",
    "      albumentations.OneOf([albumentations.MotionBlur(p=1),\n",
    "                            albumentations.OpticalDistortion(p=1),\n",
    "                            albumentations.GaussNoise(p=1)], p=1),\n",
    "      albumentations.Normalize((0.548, 0.504, 0.479), (0.237, 0.247, 0.246)),\n",
    "      albumentations.pytorch.transforms.ToTensorV2(),\n",
    "      #       이미지 원본 사이즈는 384, 512   \n",
    "  ]\n",
    ")\n",
    "\n",
    "test_transform = albumentations.Compose(\n",
    "  [\n",
    "      albumentations.Resize(600,600),\n",
    "      albumentations.Normalize((0.548, 0.504, 0.479), (0.237, 0.247, 0.246)),\n",
    "      albumentations.pytorch.transforms.ToTensorV2()\n",
    "      #       이미지 원본 사이즈는 384, 512   \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82e30155-5270-4ff4-b0ec-7e42c4b09d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17010/17010 [00:48<00:00, 347.69it/s]\n",
      "100%|██████████| 1890/1890 [00:05<00:00, 338.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./train_df.csv')\n",
    "valid_df = pd.read_csv('./valid_df.csv')\n",
    "\n",
    "dataset_train = MyDataset(path=train_df['full_path'].values,\n",
    "                          label=train_df['label'].values,\n",
    "                          transform=train_transform)\n",
    "\n",
    "dataset_valid = MyDataset(path=valid_df['full_path'].values,\n",
    "                          label=valid_df['label'].values,\n",
    "                          transform=test_transform)\n",
    "\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_dataloader = DataLoader(dataset_valid, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0454d4-4556-48dc-b908-193027e3af64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No pretrained weights exist for this model. Using random initialization.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model('efficientnet_b7', num_classes=18, pretrained=True).to(device)\n",
    "model.load_state_dict(torch.load('./epoch/e7/epoch_9_e7_0.9216931216931217.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e51aa492-8d92-4004-9f12-05f3e2bdc36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_f1_score(valid_dataloader, model, device):\n",
    "    gt_list = []\n",
    "   pred_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(valid_dataloader):\n",
    "            x = x['image'].to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            logits = model(x)\n",
    "            _, pred = torch.max(logits, 1)\n",
    "            \n",
    "            for i in y.cpu().numpy():\n",
    "                gt_list.append(i)\n",
    "            for j in pred.cpu().numpy():\n",
    "                pred_list.append(j)\n",
    "    \n",
    "    f1 = f1_score(gt_list, pred_list, average='micro')\n",
    "    del gt_list, pred_list\n",
    "    \n",
    "    print(f'Validation f1_score : {f1}')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50fb8e02-6331-467e-b54f-d96be8402217",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52f82f79-1d62-4075-95e0-b6a9934ca0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 600/2127 [07:14<18:16,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   600] loss: 0.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1200/2127 [14:25<11:04,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1200] loss: 0.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1800/2127 [21:35<03:53,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1800] loss: 0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2127/2127 [25:28<00:00,  1.39it/s]\n",
      "  0%|          | 0/237 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [00:38<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score : 0.8899470899470899\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 600/2127 [07:11<18:13,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   600] loss: 0.311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1200/2127 [14:21<11:06,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  1200] loss: 0.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1800/2127 [21:32<03:57,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,  1800] loss: 0.305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2127/2127 [25:28<00:00,  1.39it/s]\n",
      "  0%|          | 0/237 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [00:38<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score : 0.8920634920634921\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 600/2127 [07:12<18:13,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   600] loss: 0.149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1200/2127 [14:24<11:04,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  1200] loss: 0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1800/2127 [21:35<03:54,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,  1800] loss: 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2127/2127 [25:30<00:00,  1.39it/s]\n",
      "  0%|          | 0/237 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [00:38<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score : 0.964021164021164\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 600/2127 [07:12<18:11,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   600] loss: 0.082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1200/2127 [14:24<11:04,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  1200] loss: 0.095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1800/2127 [21:35<03:54,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,  1800] loss: 0.083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2127/2127 [25:30<00:00,  1.39it/s]\n",
      "  0%|          | 0/237 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [00:38<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score : 0.9624338624338624\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 600/2127 [07:11<18:12,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   600] loss: 0.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1200/2127 [14:21<11:05,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  1200] loss: 0.039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1800/2127 [21:32<03:55,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,  1800] loss: 0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2127/2127 [25:26<00:00,  1.39it/s]\n",
      "  0%|          | 0/237 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [00:38<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score : 0.9830687830687831\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 600/2127 [07:10<18:13,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   600] loss: 0.031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1200/2127 [14:22<11:04,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,  1200] loss: 0.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1800/2127 [21:33<04:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,  1800] loss: 0.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2127/2127 [25:28<00:00,  1.39it/s]\n",
      "  0%|          | 0/237 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION F1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [00:38<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation f1_score : 0.9793650793650793\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 396/2127 [04:45<20:48,  1.39it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a15ac27a6cdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;31m# Perform stepweight decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;31m# Perform optimization step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "VIS = 600\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs['image'].to(device)\n",
    "        labels = labels.to(device)\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "        if i % VIS == VIS-1:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / VIS))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    f1 = check_f1_score(valid_dataloader, model, device)\n",
    "    print(\"-\"*50)\n",
    "    torch.save(model.state_dict(), f'./epoch/epoch_{epoch}_e7_{f1}.pth')\n",
    "    \n",
    "    if epoch < NUM_EPOCHS:\n",
    "        scheduler.step()\n",
    "#         torch.save(target_model.state_dict(), f'./epoch_{epoch}_vit.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03ae89cd-10ce-4959-94d2-a0c604a0b971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/std.py:703: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 12600/12600 [00:00<00:00, 606823.18it/s]\n",
      "100%|██████████| 12600/12600 [00:34<00:00, 362.99it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "def make_test_full_path(s):\n",
    "    path = 'input/data/eval/images/'\n",
    "    return path + s\n",
    "\n",
    "test_df = pd.read_csv('input/data/eval/info.csv')\n",
    "test_df['path'] = test_df['ImageID'].progress_apply(make_test_full_path)\n",
    "\n",
    "dataset_test = TestDataset(path=test_df['path'].values,\n",
    "                         label=test_df['ans'].values,\n",
    "                         transform=test_transform)\n",
    "\n",
    "test_dataloader = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb28aa94-44a2-4269-a7cc-3a49ee755d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No pretrained weights exist for this model. Using random initialization.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model('efficientnet_b7', num_classes=18, pretrained=True).to(device)\n",
    "model.load_state_dict(torch.load('./epoch/epoch_5_e7_0.9793650793650793.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "356c4c46-281e-4f54-b7e2-99c41b497046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferences(test_dataloader, submission_df):\n",
    "    pred_list = []\n",
    "    for images in tqdm(test_dataloader):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            images = images['image'].to(device)\n",
    "            pred = model(images)\n",
    "            pred = pred.argmax(dim=-1)\n",
    "            pred_list.extend(pred.cpu().numpy())\n",
    "    submission_df['ans'] = pred_list\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3aec8b22-01be-4060-bafa-e21c1d360cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1575/1575 [04:15<00:00,  6.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc5c6e168e63498590db46022617123f1fe1268.jpg</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e72482bf56b3581c081f7da2a6180b8792c7089.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b549040c49190cedc41327748aeb197c1670f14d.jpg</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ImageID  ans\n",
       "0  cbc5c6e168e63498590db46022617123f1fe1268.jpg   14\n",
       "1  0e72482bf56b3581c081f7da2a6180b8792c7089.jpg    2\n",
       "2  b549040c49190cedc41327748aeb197c1670f14d.jpg   17\n",
       "3  4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg   14\n",
       "4  248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg   12"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv('input/data/eval/info.csv')\n",
    "submission = inferences(test_dataloader, submission_df)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a32d70d-39b0-427e-aa07-4459ef0cd7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission_0825_e7_15.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba13fea4-b2ef-43e7-b6f9-b13e7e36a0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377df5cb-94fa-4eb8-bdc3-320a0557e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(5, 5, figsize=(30, 15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
