{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b34eca7b-025f-4e68-8b38-4e0dea5f047a",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476bd615-89f2-4427-9e16-6d605ce2abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import timm\n",
    "import ttach as tta\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from sklearn.metrics import f1_score\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# from muar.augmentations import BatchRandAugment, MuAugment\n",
    "from facenet_pytorch import MTCNN\n",
    "tqdm.pandas()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device} is using!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27edf2f8-88d0-4213-b694-8efba7de363e",
   "metadata": {},
   "source": [
    "## Config Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da725a97-ae6d-4ff7-bd53-716e313f7bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## efficientnet-b7\n",
    "e7_config = {'NUM_EPOCHS' : 30,\n",
    "             'BATCH_SIZE' : 7,\n",
    "             'NUM_CLASSES' : 18,\n",
    "             'LEARNING_RATE' : 3e-4,\n",
    "             'MODEL' : 'efficientnet-b7',  # 불러올 모델 이름\n",
    "             'MODEL_NAME' : 'efficientnet-b7',  # 저장할 떄 이름\n",
    "             'NUM_WORKERS' : 1,\n",
    "             'LOG_STEPS' : 450,\n",
    "             'SAVE_PATH' : './epoch/',\n",
    "             'LOAD_MODEL' : True,  # 학습을 이어서 할 때 True\n",
    "             'LOAD_MODEL_PATH' : './epoch/e7_weight/epoch_14_e7_0.8227513227513228.pth',  # 이어서 학습할 파일의 경로\n",
    "             'BETA' : 1.0\n",
    "         }\n",
    "\n",
    "## efficientnet-b8\n",
    "e8_config = {'NUM_EPOCHS' : 30,\n",
    "             'BATCH_SIZE' : 20,\n",
    "             'NUM_CLASSES' : 18,\n",
    "             'LEARNING_RATE' : 3e-4,\n",
    "             'MODEL' : 'efficientnet-b8',  # 불러올 모델 이름\n",
    "             'MODEL_NAME' : 'efficientnet-b8',  # 저장할 떄 이름\n",
    "             'NUM_WORKERS' : 1,\n",
    "             'LOG_STEPS' : 450,\n",
    "             'SAVE_PATH' : './epoch/',\n",
    "             'LOAD_MODEL' : True,  # 학습을 이어서 할 때 True\n",
    "             'LOAD_MODEL_PATH' : './epoch/efficientnet-b8_epoch_10_0.8402953853416509.pth',  # 이어서 학습할 파일의 경로\n",
    "             'BETA' : 1.0\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae020e75-e8e1-43f6-b913-4ae5586809a4",
   "metadata": {},
   "source": [
    "## Initiate Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acede1b-b4f1-452c-a275-c41cd1e35739",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(entity=\"minibatch28\", project=\"MaskClassification\", name=\"My_Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a9fd90-8a7d-455e-baab-eeec8b84593c",
   "metadata": {},
   "source": [
    "## Augmentation Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f770dc-e5cf-471b-bc99-d27b84a30bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet-b7 augmentation\n",
    "e7_train_transform = albumentations.Compose([albumentations.Resize(600,600),\n",
    "                                             albumentations.RandomRotation(15),\n",
    "                                             albumentations.HorizontalFlip(p=0.3),\n",
    "                                             albumentations.OneOf([albumentations.ShiftScaleRotate(rotate_limit=15, p=0.5),\n",
    "                                                                   albumentations.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "                                                                   albumentations.HorizontalFlip(p=0.5),\n",
    "                                                                   albumentations.MotionBlur(p=0.5),\n",
    "                                                                   albumentations.OpticalDistortion(p=0.5),\n",
    "                                                                   albumentations.GaussNoise(p=0.5)], p=1),\n",
    "                                             albumentations.Normalize((0.548, 0.504, 0.479), (0.237, 0.247, 0.246)),\n",
    "                                             albumentations.pytorch.transforms.ToTensorV2()])\n",
    "\n",
    "e8_test_transform = albumentations.Compose([albumentations.Resize(600,600),\n",
    "                                            albumentations.Normalize((0.548, 0.504, 0.479), (0.237, 0.247, 0.246)),\n",
    "                                            albumentations.pytorch.transforms.ToTensorV2()])\n",
    "\n",
    "\n",
    "# efficientnet-b8 augmentation\n",
    "e8_train_transform = albumentations.Compose([albumentations.Resize(336,336),\n",
    "                                             albumentations.OneOf([albumentations.GaussNoise()], p=0.2),\n",
    "                                             albumentations.OneOf([albumentations.MotionBlur(p=.2),\n",
    "                                                                   albumentations.MedianBlur(blur_limit=3, p=0.1),\n",
    "                                                                   albumentations.Blur(blur_limit=3, p=0.1)], p=0.2),\n",
    "                                             albumentations.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "                                             albumentations.OneOf([albumentations.OpticalDistortion(p=0.3),\n",
    "                                                                albumentations.GridDistortion(p=.1)], p=0.2),\n",
    "                                             albumentations.OneOf([albumentations.CLAHE(clip_limit=2),\n",
    "                                                                   albumentations.Sharpen(),\n",
    "                                                                   albumentations.Emboss(),\n",
    "                                                                   albumentations.RandomBrightnessContrast()], p=0.3),\n",
    "                                             albumentations.HueSaturationValue(p=0.3),\n",
    "                                             albumentations.Cutout(num_holes=4, max_h_size=3, max_w_size=3, fill_value=0, p=0.2),\n",
    "                                             albumentations.Normalize((0.548, 0.504, 0.479), (0.237, 0.247, 0.246)),\n",
    "                                             albumentations.pytorch.transforms.ToTensorV2()])\n",
    "\n",
    "e8_test_transform = albumentations.Compose([albumentations.Resize(336,336),\n",
    "                                            albumentations.Normalize((0.548, 0.504, 0.479), (0.237, 0.247, 0.246)),\n",
    "                                            albumentations.pytorch.transforms.ToTensorV2()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2148f94b-b86b-425a-8405-62db1a658eae",
   "metadata": {},
   "source": [
    "## Read DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8843fe-d870-41d4-831f-b8d3826c8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_full_path(s):\n",
    "    path = 'input/data/eval/images/'\n",
    "    return path + s\n",
    "\n",
    "\n",
    "# 58세까지로 클래스를 잡았을 경우\n",
    "# efficientnet-b7 사용\n",
    "e7_train_df = pd.read_csv('./stratified_df/train_df.csv')\n",
    "e7_valid_df = pd.read_csv('./stratified_df/valid_df.csv')\n",
    "\n",
    "e7_test_df = pd.read_csv('./input/data/eval/info.csv')\n",
    "e7_test_df['full_path'] = test_df['ImageID'].progress_apply(make_test_full_path)\n",
    "e7_submission_df = pd.read_csv('./input/data/eval/info.csv')\n",
    "\n",
    "# 60세까지로 클래스를 잡았을 경우\n",
    "# efficientnet-b8 사용\n",
    "e8_train_df = pd.read_csv('./stratified_df/train_df_0901.csv')\n",
    "e8_valid_df = pd.read_csv('./stratified_df/valid_df_0901.csv')\n",
    "\n",
    "e8_test_df = pd.read_csv('./input/data/eval/info.csv')\n",
    "e8_test_df['full_path'] = test_df['ImageID'].progress_apply(make_test_full_path)\n",
    "e8_submission_df = pd.read_csv('./input/data/eval/info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e38ba-6f17-437e-b788-c9ba4fa24ab1",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b494bad7-520d-484b-b574-33915b98aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class E7TrainDataset(Dataset):\n",
    "    def __init__(self, path, label, transform):\n",
    "        img_list = []\n",
    "        for p in tqdm(path):\n",
    "            img = cv2.imread(p)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_list.append(img)\n",
    "        \n",
    "        self.X = img_list\n",
    "        self.y = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        len_dataset = len(self.X)\n",
    "        return len_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X,y = self.X[idx], self.y[idx]\n",
    "        X = self.transform(image=X)['image']\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "class E8TrainDataset(Dataset):\n",
    "    def __init__(self, path, label, transform):\n",
    "        img_list = []\n",
    "        for p in tqdm(path):\n",
    "            img = cv2.imread(p)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # 얼굴 탐색\n",
    "            mtcnn = MTCNN()\n",
    "            boxes, prob = mtcnn.detect(img)\n",
    "            \n",
    "            # 얼굴을 찾지 못하는 경우\n",
    "            if not isinstance(boxes, np.ndarray):\n",
    "                img = img[110:382, 90:287]\n",
    "            \n",
    "            # 얼굴을 찾은 경우\n",
    "            else:\n",
    "                xmin, ymin, xmax, ymax = map(int, boxes[0])\n",
    "                # 표준편차로 얼굴 주변까지 일부 확보\n",
    "                xmin, ymin, xmax, ymax = abs(xmin)-19, abs(ymin)-35, abs(xmax)+20, abs(ymax)+38\n",
    "                if xmin <= 0: xmin = 0\n",
    "                if ymin <= 0: ymin = 0\n",
    "                img = img[ymin:ymax, xmin:xmax]\n",
    "            \n",
    "            img_list.append(img)\n",
    "        \n",
    "        self.X = img_list\n",
    "        self.y = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        len_dataset = len(self.X)\n",
    "        return len_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X,y = self.X[idx], self.y[idx]\n",
    "        X = self.transform(image=X)['image']\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2737109-59dd-44d7-a107-c2d88d865705",
   "metadata": {},
   "outputs": [],
   "source": [
    "class E7TestDataset(Dataset):\n",
    "    def __init__(self, path, label, transform):\n",
    "        img_list = []\n",
    "        for p in tqdm(path):\n",
    "            img = cv2.imread(p)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_list.append(img)\n",
    "        \n",
    "        self.X = img_list\n",
    "        self.y = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        len_dataset = len(self.X)\n",
    "        return len_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X,y = self.X[idx], self.y[idx]\n",
    "        X = self.transform(image=X)['image']\n",
    "        return X\n",
    "    \n",
    "\n",
    "class E8TestDataset(Dataset):\n",
    "    def __init__(self, path, label, transform):\n",
    "        img_list = []\n",
    "        for p in tqdm(path):\n",
    "            img = cv2.imread(p)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # 얼굴 탐색\n",
    "            mtcnn = MTCNN()\n",
    "            boxes, prob = mtcnn.detect(img)\n",
    "            \n",
    "            # 얼굴을 찾지 못하는 경우\n",
    "            if not isinstance(boxes, np.ndarray):\n",
    "                img = img[110:382, 90:287]\n",
    "            \n",
    "            # 얼굴을 찾은 경우\n",
    "            else:\n",
    "                xmin, ymin, xmax, ymax = map(int, boxes[0])\n",
    "                # 표준편차로 얼굴 주변까지 일부 확보\n",
    "                xmin, ymin, xmax, ymax = abs(xmin)-19, abs(ymin)-35, abs(xmax)+20, abs(ymax)+38\n",
    "                if xmin <= 0: xmin = 0\n",
    "                if ymin <= 0: ymin = 0\n",
    "                img = img[ymin:ymax, xmin:xmax]\n",
    "            \n",
    "            img_list.append(img)\n",
    "        \n",
    "        self.X = img_list\n",
    "        self.y = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        len_dataset = len(self.X)\n",
    "        return len_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X,y = self.X[idx], self.y[idx]\n",
    "        X = self.transform(image=X)['image']\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f55194-f3d2-41d0-a265-dd396f337689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df, transform, train=True):\n",
    "    if train:\n",
    "        dataset = TrainDataset(path=df['full_path'].values,\n",
    "                               label=df['label'].values,\n",
    "                               transform=transform)\n",
    "    else:\n",
    "        dataset = TestDataset(path=df['full_path'].values,\n",
    "                              label=df['ans'].values,\n",
    "                              transform=transform)\n",
    "    return dataset\n",
    "\n",
    "def get_loader(dataset, config, shuffle=True):\n",
    "    loader = DataLoader(dataset, batch_size=config['BATCH_SIZE'], shuffle=shuffle, \n",
    "                        num_workers=config['NUM_WORKERS'], pin_memory=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb575dc-2502-43c1-9aff-4fbbc9d0081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet-b7\n",
    "dataset_train = get_dataset(e7_train_df, e7_train_transform, train=True)\n",
    "dataset_valid = get_dataset(e7_valid_df, e7_test_transform, train=True)\n",
    "\n",
    "train_dataloader = get_loader(e7_dataset_train, e7_config, shuffle=True)\n",
    "valid_dataloader = get_loader(e7_dataset_valid, e7_config, shuffle=False)\n",
    "\n",
    "# efficientnet-b8\n",
    "dataset_train = get_dataset(e8_train_df, e8_train_transform, train=True)\n",
    "dataset_valid = get_dataset(e8_valid_df, e8_test_transform, train=True)\n",
    "\n",
    "train_dataloader = get_loader(e8_dataset_train, e8_config, shuffle=True)\n",
    "valid_dataloader = get_loader(e8_dataset_valid, e8_config, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb22fff2-8e81-42d2-a85d-68675f4195ff",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f352cb-3e85-4e11-a258-ba0c2d64377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet-b8\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.net = EfficientNet.from_pretrained(config['MODEL'], num_classes=1024, advprop=True).to(device)\n",
    "        self.fc = nn.Sequential(nn.Linear(1024,512),\n",
    "                                nn.LeakyReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(512,config['NUM_CLASSES'])).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf958048-4ee1-42a8-8481-268a85e95378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2] \n",
    "    H = size[3] \n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)  \n",
    "\n",
    "    # 패치의 중앙 좌표 값 cx, cy\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    # 패치 모서리 좌표 값 \n",
    "    bbx1 = 0\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = W\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b79c8e-c224-410d-8e0a-61eba94180e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def e7_train(model, config, train_dataloader, device):\n",
    "    running_loss = 0.0\n",
    "    log_step_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for step, (inputs, labels) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, labels)        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        log_step_loss += loss.item()\n",
    "        \n",
    "        if step % config['LOG_STEPS'] == config['LOG_STEPS'] - 1:\n",
    "            step_loss = log_step_loss / config['LOG_STEPS']\n",
    "            print(f'Traning Steps : {step + 1} Traning Loss : {step_loss}')\n",
    "            log_step_loss = 0.0\n",
    "            \n",
    "    scheduler.step()\n",
    "    return running_loss\n",
    "\n",
    "def e8_train(model, config, train_dataloader, device):\n",
    "    running_loss = 0.0\n",
    "    log_step_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for step, (inputs, labels) in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        if config['BETA'] > 0 and np.random.random() > 0.5: # cutmix가 실행될 경우     \n",
    "            lam = np.random.beta(config['BETA'], config['BETA'])\n",
    "            rand_index = torch.randperm(inputs.size()[0]).to(device)\n",
    "            target_a = labels # 원본 이미지 label\n",
    "            target_b = labels[rand_index] # 패치 이미지 label       \n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(inputs.size(), lam)\n",
    "            inputs[:, :, bbx1:bbx2, bby1:bby2] = inputs[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (inputs.size()[-1] * inputs.size()[-2]))\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, target_a) * lam + criterion(logits, target_b) * (1. - lam)\n",
    "        \n",
    "        else: # cutmix가 실행되지 않았을 경우\n",
    "            logits = model(inputs) \n",
    "            loss= criterion(logits, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        log_step_loss += loss.item()\n",
    "        \n",
    "        if step % config['LOG_STEPS'] == config['LOG_STEPS'] - 1:\n",
    "            step_loss = log_step_loss / config['LOG_STEPS']\n",
    "            print(f'Traning Steps : {step + 1} Traning Loss : {step_loss}')\n",
    "            log_step_loss = 0.0\n",
    "            \n",
    "    scheduler.step()\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b80c75-e928-4445-b6dc-f012e8180cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, valid_dataloader, device):\n",
    "    gt_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(valid_dataloader):\n",
    "            x = x.to(device).float()\n",
    "            y = y.to(device)\n",
    "            \n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, pred = torch.max(logits, 1)\n",
    "            correct += torch.sum(pred == y.data)\n",
    "            \n",
    "            for i in y.cpu().numpy():\n",
    "                gt_list.append(i)\n",
    "            for j in pred.cpu().numpy():\n",
    "                pred_list.append(j)\n",
    "    \n",
    "    f1 = f1_score(gt_list, pred_list, average='macro')\n",
    "    acc = correct / dataset_valid.__len__()\n",
    "    del gt_list, pred_list\n",
    "    \n",
    "    print(f'Validation f1_score : {f1}')\n",
    "    print(f'Validation accuracy : {acc}')\n",
    "    return f1, acc, running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689f413-e99a-401b-bf38-503479245c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, config, train_dataloader, valid_dataloader, device):\n",
    "    best_f1 = 0.0\n",
    "    best_valid_loss = 1e9\n",
    "    for epoch in range(config['NUM_EPOCHS']):\n",
    "        print(f'Epoch : {epoch + 1}')\n",
    "        train_loss = train(model, config, train_dataloader, device)\n",
    "        f1, acc, valid_loss = valid(model, valid_dataloader, device)\n",
    "        \n",
    "        wandb.log({'Train Loss': train_loss,\n",
    "                   'Validation Loss': valid_loss,\n",
    "                   'Validation F1': f1,\n",
    "                   'Validation Acc': acc})\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            save_path = config['SAVE_PATH']\n",
    "            model_name = config['MODEL_NAME']\n",
    "            torch.save(model.state_dict(), f'{save_path}/{model_name}_epoch_{epoch}_{best_f1}.pth')\n",
    "        \n",
    "        elif valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            save_path = config['SAVE_PATH']\n",
    "            model_name = config['MODEL_NAME']\n",
    "            torch.save(model.state_dict(), f'{save_path}/{model_name}_epoch_{epoch}_{best_f1}.pth')\n",
    "        else:\n",
    "            torch.save(model.state_dict(), f'{save_path}/{model_name}_epoch_{epoch}_0831.pth')\n",
    "        print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcccf4db-b76e-4be2-bb67-ab3050a6aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2, reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        \n",
    "        return F.nll_loss(((1 - prob) ** self.gamma) * log_prob,\n",
    "                           target_tensor,\n",
    "                          weight=self.weight,\n",
    "                          reduction=self.reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed5e27f-dc19-4978-8652-74e059bd3b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "e7_model = EfficientNet.from_pretrained(e7_config['MODEL'], num_classes=1024, advprop=True).to(device)\n",
    "if e7_config['LOAD_MODEL']:\n",
    "    e7_model.load_state_dict(torch.load(e7_config['LOAD_MODEL_PATH']))\n",
    "    \n",
    "e8_model = Net(config)\n",
    "if e8_config['LOAD_MODEL']:\n",
    "    e8_model.load_state_dict(torch.load(e8_config['LOAD_MODEL_PATH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f1aa33-ccb4-4bff-ac5e-e464a276123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet-b7\n",
    "classes = e7_train_df['label'].value_counts().sort_index().values\n",
    "class_weight = torch.tensor(np.max(classes) / classes).to(device, dtype=torch.float)\n",
    "e7_criterion = nn.CrossEntropyLoss(weight=class_weight)\n",
    "e7_optimizer = AdamW(e7_model.parameters(), lr=e7_config['LEARNING_RATE'])\n",
    "e7_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.7)\n",
    "\n",
    "# efficientnet-b8\n",
    "e8_criterion = FocalLoss()\n",
    "e8_optimizer = AdamW(e8_model.parameters(), lr=e8_config['LEARNING_RATE'])\n",
    "e8_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11482bbd-cc57-41be-9b1b-984f13dd68c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet-b8\n",
    "run(e7_model, e7_config, e7_train_dataloader, e7_valid_dataloader, device)\n",
    "\n",
    "# efficientnet-b8\n",
    "run(e8_model, e8_config, e8_train_dataloader, e8_valid_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac828c3-9313-46c0-95b3-5b1cc26fca0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
