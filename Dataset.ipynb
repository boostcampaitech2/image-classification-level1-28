{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18027227-b715-431d-88cf-fe1d55206940",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6c693b-8a00-4a77-8c85-10c212680012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import timm\n",
    "import ttach as tta\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from sklearn.metrics import f1_score\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device} is using!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb65940e-229e-4f95-8d75-209e27e9b84f",
   "metadata": {},
   "source": [
    "## Config Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b89bd7-404b-415a-8912-c190004cdfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'NUM_EPOCHS' : 15,\n",
    "          'BATCH_SIZE' : 8,\n",
    "          'NUM_CLASSES' : 18,\n",
    "          'LEARNING_RATE' : 1e-4,\n",
    "          'MODEL' : 'nf_resnet50',  # 불러올 모델 이름\n",
    "          'MODEL_NAME' : 'nf_resnet50',  # 저장할 떄 이름\n",
    "          'NUM_WORKERS' : 2,\n",
    "          'LOG_STEPS' : 450,\n",
    "          'SAVE_PATH' : './epoch/',\n",
    "          'LOAD_MODEL' : False,  # 학습을 이어서 할 때 True\n",
    "          'LOAD_MODEL_PATH' : './epoch/nf_resnet50_epoch_4_0.7522671719026435.pth'  # 이어서 학습할 파일의 경로\n",
    "         }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc308f-b7b5-4d99-99c8-7788e6546489",
   "metadata": {},
   "source": [
    "## Augmentation Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae3374a-8f33-44ad-997a-e2bf45d07dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = albumentations.Compose(\n",
    "  [\n",
    "      albumentations.Resize(256,256),\n",
    "#       albumentations.RandomRotation(15),\n",
    "#       albumentations.HorizontalFlip(p=0.3),\n",
    "      albumentations.OneOf([albumentations.ShiftScaleRotate(rotate_limit=15, p=0.5),\n",
    "                            albumentations.RandomBrightnessContrast(p=0.5),\n",
    "                            albumentations.MotionBlur(p=0.5),\n",
    "                            albumentations.OpticalDistortion(p=0.5),\n",
    "                            albumentations.GaussNoise(p=0.5)], p=1),\n",
    "      albumentations.Normalize((0.548, 0.504, 0.479), (0.237, 0.247, 0.246)),\n",
    "      albumentations.pytorch.transforms.ToTensorV2(),\n",
    "      #       이미지 원본 사이즈는 384, 512   \n",
    "  ]\n",
    ")\n",
    "\n",
    "test_transform = albumentations.Compose(\n",
    "  [\n",
    "      albumentations.Resize(288,288),\n",
    "      albumentations.Normalize((0.548, 0.504, 0.479), (0.237, 0.247, 0.246)),\n",
    "      albumentations.pytorch.transforms.ToTensorV2()\n",
    "      #       이미지 원본 사이즈는 384, 512   \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becdcc84-7406-4edd-a00e-bb58a1f869c7",
   "metadata": {},
   "source": [
    "## Read DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcafbfa-4bf3-4524-910d-6815d9bc77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_test_full_path(s):\n",
    "    path = 'input/data/eval/images/'\n",
    "    return path + s\n",
    "\n",
    "train_df = pd.read_csv('./stratified_df/train_df.csv')\n",
    "valid_df = pd.read_csv('./stratified_df/valid_df.csv')\n",
    "test_df = pd.read_csv('./input/data/eval/info.csv')\n",
    "test_df['full_path'] = test_df['ImageID'].progress_apply(make_test_full_path)\n",
    "submission_df = pd.read_csv('./input/data/eval/info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f19a7d6-b82e-45bf-bfd2-821d1f105ff3",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4be2e3-e1bf-401d-a746-3e08a624a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, path, label, transform):\n",
    "        img_list = []\n",
    "        for p in tqdm(path):\n",
    "            img = cv2.imread(p)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_list.append(img)\n",
    "        \n",
    "        self.X = img_list\n",
    "        self.y = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        len_dataset = len(self.X)\n",
    "        return len_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X,y = self.X[idx], self.y[idx]\n",
    "        X = self.transform(image=X)['image']\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76012de7-bb71-468b-b135-786439648026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, path, label, transform):\n",
    "        img_list = []\n",
    "        for p in tqdm(path):\n",
    "            img = cv2.imread(p)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_list.append(img)\n",
    "        \n",
    "        self.X = img_list\n",
    "        self.y = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        len_dataset = len(self.X)\n",
    "        return len_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X,y = self.X[idx], self.y[idx]\n",
    "        X = self.transform(image=X)['image']\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536915c8-e29b-4664-8b75-040ceead26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df, transform, train=True):\n",
    "    if train:\n",
    "        dataset = TrainDataset(path=df['full_path'].values,\n",
    "                               label=df['label'].values,\n",
    "                               transform=transform)\n",
    "    else:\n",
    "        dataset = TestDataset(path=df['full_path'].values,\n",
    "                              label=df['ans'].values,\n",
    "                              transform=transform)\n",
    "    return dataset\n",
    "\n",
    "def get_loader(dataset, config, shuffle=True):\n",
    "    loader = DataLoader(dataset, batch_size=config['BATCH_SIZE'], shuffle=shuffle, \n",
    "                        num_workers=config['NUM_WORKERS'], pin_memory=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1389c-ad03-4440-ac41-b9c9be3c7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = get_dataset(train_df, train_transform, train=True)\n",
    "dataset_valid = get_dataset(valid_df, test_transform, train=True)\n",
    "\n",
    "train_dataloader = get_loader(dataset_train, config, shuffle=True)\n",
    "valid_dataloader = get_loader(dataset_valid, config, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
