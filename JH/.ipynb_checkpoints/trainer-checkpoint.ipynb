{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6c693b-8a00-4a77-8c85-10c212680012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/std.py:703: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from sklearn.metrics import f1_score\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b89bd7-404b-415a-8912-c190004cdfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is using!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device} is using!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91942fb-d83d-4570-bb44-fbb52ee3b7fb",
   "metadata": {},
   "source": [
    "## WandB INIT, Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae3374a-8f33-44ad-997a-e2bf45d07dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminibatch28\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">JH_efficientnet-b7_facecrop_cutmix_F1loss_7_0.0003_cosine</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/minibatch28/MaskClassification\" target=\"_blank\">https://wandb.ai/minibatch28/MaskClassification</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/minibatch28/MaskClassification/runs/2s1ny2ho\" target=\"_blank\">https://wandb.ai/minibatch28/MaskClassification/runs/2s1ny2ho</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/git/JH/wandb/run-20210829_161713-2s1ny2ho</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(2s1ny2ho)</h1><iframe src=\"https://wandb.ai/minibatch28/MaskClassification/runs/2s1ny2ho\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0a7c599af0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "config={\n",
    "    \"user\" : \"JH\",\n",
    "    \"lr\": 3e-4,\n",
    "    \"architecture\": \"efficientnet-b5\",\n",
    "    \"dataset\": \"facecrop\",\n",
    "    \"augmentation\" : \"cutmix\",\n",
    "    \"loss\" : \"F1loss\",\n",
    "    \"gamma\" : 0.9,\n",
    "    \"scheduler\" : \"cosine\",\n",
    "    \"batch_size\" : 16,\n",
    "    \"epochs\" : 30,\n",
    "    \"beta\" : 1.0,\n",
    "    \"memo\" : \"MSD3\"\n",
    "}\n",
    "config['model'] = '_'.join([config['user'], config['architecture'], config[\"memo\"], config['dataset'], config['augmentation'], config['loss'], str(config['batch_size']), str(config['lr']), config[\"scheduler\"]])\n",
    "wandb.init(entity=\"minibatch28\", project=\"MaskClassification\", name=config['model'], config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b8c32-03ca-4436-8f83-fd5edf96e81c",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fcafbfa-4bf3-4524-910d-6815d9bc77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path, label, transform):\n",
    "        img_list = []\n",
    "        for p in tqdm(path):\n",
    "            img = cv2.imread(p)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_list.append(img)\n",
    "        \n",
    "        self.X = img_list\n",
    "        self.y = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        len_dataset = len(self.X)\n",
    "        return len_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X,y = self.X[idx], self.y[idx]\n",
    "        X = self.transform(image=X)['image']  # transforms를 사용하시는 분은 X = self.transform(X)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc4be2e3-e1bf-401d-a746-3e08a624a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, path, transform):\n",
    "        img_list = []\n",
    "        for p in tqdm(path):\n",
    "            img = cv2.imread(p)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_list.append(img)\n",
    "        \n",
    "        self.X = img_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        len_dataset = len(self.X)\n",
    "        return len_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        X = self.transform(image=X)['image']  # transforms를 사용하시는 분은 X = self.transform(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76012de7-bb71-468b-b135-786439648026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation은 각자 방식대로\n",
    "\n",
    "train_transform = albumentations.Compose(\n",
    "  [\n",
    "      albumentations.Resize(456,456),\n",
    "#       albumentations.RandomRotation(15),\n",
    "      albumentations.HorizontalFlip(p=0.5),\n",
    "      albumentations.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.6),\n",
    "      albumentations.RandomBrightnessContrast(brightness_limit=0.1, p=0.6),\n",
    "      albumentations.GaussNoise(p=0.5),\n",
    "      albumentations.MotionBlur(p=0.5),\n",
    "      albumentations.OpticalDistortion(p=0.5),\n",
    "      albumentations.Normalize((0.548, 0.504, 0.479), (0.237, 0.247, 0.246)),\n",
    "      albumentations.pytorch.transforms.ToTensorV2(),\n",
    "      #       이미지 원본 사이즈는 384, 512   \n",
    "  ]\n",
    ")\n",
    "\n",
    "test_transform = albumentations.Compose(\n",
    "  [\n",
    "      albumentations.Resize(456,456),\n",
    "      albumentations.Normalize((0.548, 0.504, 0.479), (0.237, 0.247, 0.246)),\n",
    "      albumentations.pytorch.transforms.ToTensorV2()\n",
    "      #       이미지 원본 사이즈는 384, 512   \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc68e9a-a5a9-4078-8829-50e6bcbbd13c",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "536915c8-e29b-4664-8b75-040ceead26a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15120/15120 [00:21<00:00, 714.83it/s]\n",
      "100%|██████████| 3780/3780 [00:05<00:00, 715.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# DF 읽어오기\n",
    "train_df = pd.read_csv('/opt/ml/input/face_train_df.csv')\n",
    "valid_df = pd.read_csv('/opt/ml/input/face_valid_df.csv')\n",
    "\n",
    "# Dataset 객체 생성\n",
    "dataset_train = MyDataset(path=train_df['full_path'].values,\n",
    "                          label=train_df['label'].values,\n",
    "                          transform=train_transform)\n",
    "\n",
    "dataset_valid = MyDataset(path=valid_df['full_path'].values,\n",
    "                          label=valid_df['label'].values,\n",
    "                          transform=test_transform)\n",
    "\n",
    "# Loader 올리기\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=config['batch_size'], shuffle=True, num_workers=3, pin_memory=True)\n",
    "valid_dataloader = DataLoader(dataset_valid, batch_size=config['batch_size'], shuffle=False, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68a251fd-fd65-4f39-9d9d-453e71e33dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.backbone = EfficientNet.from_pretrained(config['architecture'], num_classes=1024)\n",
    "        self.fc = nn.Linear(1024, 18)\n",
    "        self.ms1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            self.fc\n",
    "        )\n",
    "        self.ms2 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            self.fc\n",
    "        )\n",
    "        self.ms3 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            self.fc\n",
    "        )\n",
    "        self.num_samples = 3\n",
    "        self.best_f1 = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = backbone(x)\n",
    "        output1 = ms1(x)\n",
    "        output2 = ms2(x)\n",
    "        output3 = ms3(x)\n",
    "        \n",
    "        x = (output1 + output2 = output3) / self.num_samples\n",
    "        return x\n",
    "        \n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f19dce-5710-4389-bfc4-831179451747",
   "metadata": {},
   "source": [
    "## Loss, Optimizer, Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483bcda5-1023-47c6-8e92-eb8a11f41b49",
   "metadata": {},
   "source": [
    "### Weightedloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f7f9510-518f-49e4-8bce-3560d6ab7efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0904, 0.1211, 0.5981, 0.0678, 0.0608, 0.4554, 0.4472, 0.7905, 1.3867,\n",
      "        0.3419, 0.3710, 0.9658, 0.4472, 0.7905, 1.3867, 0.3419, 0.3710, 0.9658],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim \n",
    "\n",
    "class_distribution = torch.tensor([2745, 2050, 415, 3660, 4085, 545, \n",
    "                      555, 314, 179, 726, 669, 257, \n",
    "                      555, 314, 179, 726, 669, 257])\n",
    "normedWeights = [1 - (x / sum(class_distribution)) for x in class_distribution]\n",
    "loss_distribution = class_distribution / class_distribution.sum()\n",
    "loss_distribution = 1.0 / loss_distribution\n",
    "loss_distribution = (loss_distribution / loss_distribution.sum()*10).to(device)\n",
    "print(loss_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7298061-b0bc-4d0d-a493-c33774ceb750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     0: adjusting learning rate of group 0 to 3.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "# https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354\n",
    "class F1Loss(nn.Module):\n",
    "    def __init__(self, classes=18, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.epsilon = epsilon\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "\n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)\n",
    "        return 1 - f1.mean()\n",
    "\n",
    "criterion = F1Loss()\n",
    "# criterion = nn.CrossEntropyLoss(weight=loss_distribution)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=config['gamma'], verbose=True)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=6, T_mult=1, eta_min=5e-6, last_epoch=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d084d084-6067-4b15-a7f7-08a6f1413e61",
   "metadata": {},
   "source": [
    "## Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d84c8f2-0f11-4adc-a4ec-eeb763e06b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def check():\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    counter = 0\n",
    "    y_true = []\n",
    "    y_predicted = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_dataloader:\n",
    "            counter += 1\n",
    "            y_true += y.tolist()\n",
    "            \n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "    \n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            y_predicted += predictions.tolist()\n",
    "            \n",
    "            \n",
    "            loss = criterion(scores, y)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "#     print(y_true, y_predicted)\n",
    "    cm = confusion_matrix(y_true, y_predicted)\n",
    "    F1 = []\n",
    "    epsilon = 1e-7\n",
    "    for c in range(18):\n",
    "        precision = cm[c][c] / (np.sum(cm, axis=0)[c] + epsilon)\n",
    "        recall = cm[c][c] / (np.sum(cm, axis=1)[c] + epsilon)\n",
    "        f = 2 * precision * recall / (precision + recall)\n",
    "        if np.isnan(f):\n",
    "            f = 0\n",
    "        F1.append(f)\n",
    "    macro_F1 = np.mean(F1)\n",
    "    \n",
    "    print(\"< VALIDATION >\")\n",
    "    print(\"*\"*73)\n",
    "    print(\"Validation Loss :\", val_loss/counter)\n",
    "    print(\"-\"*73)\n",
    "    print(\"Total Accuracy\")\n",
    "    print(accuracy_score(y_true, y_predicted) * 100, \"%\")\n",
    "    print(\"-\"*73)\n",
    "    print(\"Confusion Matrix\")\n",
    "    for row in cm:\n",
    "        for c in row:\n",
    "            print(str(c).ljust(4), end='')\n",
    "        print()\n",
    "    print(\"-\"*73)\n",
    "    print(\"Validation F1 score :\" , macro_F1)\n",
    "    for c, f in enumerate(F1):\n",
    "        print(\"Class\", c, \":\", f)\n",
    "        \n",
    "    if model.best_f1 < macro_F1:\n",
    "        model.best_f1 = macro_F1\n",
    "#     if model.best_valid > val_loss/counter:\n",
    "#         model.best_valid = val_loss/counter\n",
    "        torch.save(model.state_dict(), '/opt/ml/weights/{}/{:.4f}.pt'.format(config['model'], model.best_f1))\n",
    "    print(\"model saved!\")\n",
    "    print(\"*\"*73)\n",
    "    print()\n",
    "    wandb.log({\n",
    "        \"Validation Loss\" : val_loss/counter, \n",
    "        \"Validation Total Accuracy\" :accuracy_score(y_true, y_predicted) * 100, \n",
    "        \"Validation F1\" : macro_F1,\n",
    "        \"Learning Rate\" : scheduler.get_last_lr()[0]*10000\n",
    "    })\n",
    "        \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b73d78-fe46-4277-84fc-7c6076ce517b",
   "metadata": {},
   "source": [
    "## Cutmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "150e9923-e07f-4615-9e2a-548d393389d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam): # size : [Batch_size, Channel, Width, Height]\n",
    "    W = size[2] \n",
    "    H = size[3] \n",
    "    cut_rat = np.sqrt(1. - lam)  # 패치 크기 비율\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)  \n",
    "\n",
    "   \t# 패치의 중앙 좌표 값 cx, cy\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\t\t\n",
    "    # 패치 모서리 좌표 값 \n",
    "    bbx1 = 0\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = W\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "   \n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84d2e8-56d4-4040-b4c7-292cb834c9f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8146753c-ff39-4146-9e7e-b93bb0bb126c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1080/2160 [24:23<24:18,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.872126336785845\n",
      "Train Accuracy : 41.77349015461874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-f0f531eb0249>:34: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f = 2 * precision * recall / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< VALIDATION >\n",
      "*************************************************************************\n",
      "Validation Loss : 0.8833198781366701\n",
      "-------------------------------------------------------------------------\n",
      "Total Accuracy\n",
      "72.61904761904762 %\n",
      "-------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "514 3   1   9   22  0   1   0   0   0   0   0   0   0   0   0   0   0   \n",
      "30  172 36  0   74  3   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "0   105 61  0   14  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "25  1   0   639 54  3   0   0   0   5   3   0   0   0   0   0   0   0   \n",
      "1   8   0   20  619 20  0   0   0   0   2   0   0   0   0   0   0   0   \n",
      "0   8   6   0   224 17  0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "2   0   0   0   0   0   101 0   0   4   2   0   1   0   0   0   0   0   \n",
      "0   0   5   0   5   0   7   40  0   0   6   0   0   0   0   0   0   0   \n",
      "0   0   2   0   0   1   0   32  0   0   1   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   4   1   0   130 7   0   0   0   0   4   0   0   \n",
      "0   1   1   0   27  1   0   1   0   3   100 0   0   0   0   0   0   0   \n",
      "0   0   0   0   10  2   0   0   0   0   39  0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   106 0   0   4   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   20  42  0   0   1   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   36  0   0   0   0   \n",
      "0   0   0   0   1   0   0   0   0   0   0   0   5   0   0   140 0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   10  20  0   40  64  0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   1   16  0   3   31  0   \n",
      "-------------------------------------------------------------------------\n",
      "Validation F1 score : 0.5230245227429735\n",
      "Class 0 : 0.9162210337047736\n",
      "Class 1 : 0.5611745512035319\n",
      "Class 2 : 0.41780821889191216\n",
      "Class 3 : 0.9141630899979739\n",
      "Class 4 : 0.7197674417767712\n",
      "Class 5 : 0.11258278138239551\n",
      "Class 6 : 0.9058295956001529\n",
      "Class 7 : 0.5839416049869466\n",
      "Class 8 : 0\n",
      "Class 9 : 0.9027777771508488\n",
      "Class 10 : 0.6802721083807672\n",
      "Class 11 : 0\n",
      "Class 12 : 0.8379446633692138\n",
      "Class 13 : 0.47457627065019636\n",
      "Class 14 : 0\n",
      "Class 15 : 0.8308605336315369\n",
      "Class 16 : 0.5565217386465029\n",
      "Class 17 : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1081/2160 [26:08<9:41:59, 32.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved!\n",
      "*************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 2159/2160 [50:27<00:01,  1.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.8564244001827858\n",
      "Train Accuracy : 45.61507936507937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-f0f531eb0249>:34: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f = 2 * precision * recall / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< VALIDATION >\n",
      "*************************************************************************\n",
      "Validation Loss : 0.8732572574306418\n",
      "-------------------------------------------------------------------------\n",
      "Total Accuracy\n",
      "74.15343915343915 %\n",
      "-------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "539 0   0   10  0   0   1   0   0   0   0   0   0   0   0   0   0   0   \n",
      "49  136 76  0   36  17  0   0   0   0   1   0   0   0   0   0   0   0   \n",
      "0   72  81  0   4   23  0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "54  0   0   672 0   1   0   0   0   3   0   0   0   0   0   0   0   0   \n",
      "15  0   0   72  468 114 0   0   0   0   1   0   0   0   0   0   0   0   \n",
      "4   0   0   0   150 101 0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "2   0   0   0   0   0   106 1   0   1   0   0   0   0   0   0   0   0   \n",
      "0   0   1   0   1   1   3   50  0   0   7   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   32  0   0   4   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   12  0   0   130 2   0   0   0   0   2   0   0   \n",
      "0   0   0   0   6   2   2   2   0   4   118 0   0   0   0   0   0   0   \n",
      "1   0   0   0   0   5   0   1   0   0   44  0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   109 0   0   1   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   5   36  0   0   22  0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   26  0   0   10  0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   10  0   0   134 2   0   \n",
      "0   0   0   0   1   1   0   0   0   0   0   0   2   0   0   7   123 0   \n",
      "0   0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   47  0   \n",
      "-------------------------------------------------------------------------\n",
      "Validation F1 score : 0.5712351145797359\n",
      "Class 0 : 0.8879736407103833\n",
      "Class 1 : 0.520076481636682\n",
      "Class 2 : 0.47928994054479884\n",
      "Class 3 : 0.9056603772364339\n",
      "Class 4 : 0.7005988022903296\n",
      "Class 5 : 0.3854961830589709\n",
      "Class 6 : 0.9059829052085616\n",
      "Class 7 : 0.6711409386964552\n",
      "Class 8 : 0\n",
      "Class 9 : 0.9154929571017655\n",
      "Class 10 : 0.758842443241902\n",
      "Class 11 : 0\n",
      "Class 12 : 0.923728812776501\n",
      "Class 13 : 0.5759999990784\n",
      "Class 14 : 0\n",
      "Class 15 : 0.9241379303971463\n",
      "Class 16 : 0.727810650456917\n",
      "Class 17 : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2160/2160 [52:12<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved!\n",
      "*************************************************************************\n",
      "\n",
      "Epoch     1: adjusting learning rate of group 0 to 2.8024e-04.\n",
      "Epoch : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 1080/2160 [24:22<24:14,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.8233401390493853\n",
      "Train Accuracy : 54.31478789480639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-f0f531eb0249>:34: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f = 2 * precision * recall / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< VALIDATION >\n",
      "*************************************************************************\n",
      "Validation Loss : 0.8709594286150403\n",
      "-------------------------------------------------------------------------\n",
      "Total Accuracy\n",
      "76.37566137566138 %\n",
      "-------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "537 2   0   6   0   1   4   0   0   0   0   0   0   0   0   0   0   0   \n",
      "42  266 7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "0   121 59  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "47  1   0   668 9   3   0   0   0   1   0   0   0   1   0   0   0   0   \n",
      "19  79  0   20  450 102 0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "0   38  0   0   127 90  0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "2   0   0   0   0   0   107 0   0   1   0   0   0   0   0   0   0   0   \n",
      "0   2   0   0   0   0   6   54  0   0   1   0   0   0   0   0   0   0   \n",
      "0   0   1   0   0   0   0   35  0   0   0   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   10  0   0   134 0   0   0   0   0   2   0   0   \n",
      "0   0   0   0   2   7   2   13  0   7   102 1   0   0   0   0   0   0   \n",
      "0   0   0   0   0   3   0   9   0   0   31  8   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   108 0   0   2   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   8   55  0   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   35  1   0   0   0   \n",
      "0   0   0   0   0   1   0   0   0   0   0   0   3   2   0   138 2   0   \n",
      "0   0   0   0   0   7   0   0   0   0   0   0   2   9   0   6   110 0   \n",
      "0   0   0   0   0   6   0   0   0   0   0   0   0   4   0   0   41  0   \n",
      "-------------------------------------------------------------------------\n",
      "Validation F1 score : 0.603877442117798\n",
      "Class 0 : 0.8972431076195082\n",
      "Class 1 : 0.6456310678044586\n",
      "Class 2 : 0.47773279313543904\n",
      "Class 3 : 0.9382022470592412\n",
      "Class 4 : 0.7154213035428584\n",
      "Class 5 : 0.37894736826149583\n",
      "Class 6 : 0.8953974887904623\n",
      "Class 7 : 0.6206896544589774\n",
      "Class 8 : 0\n",
      "Class 9 : 0.9273356394966537\n",
      "Class 10 : 0.761194029282691\n",
      "Class 11 : 0.26666666577777776\n",
      "Class 12 : 0.9350649342553551\n",
      "Class 13 : 0.6508875731942159\n",
      "Class 14 : 0.05405405376186998\n",
      "Class 15 : 0.9387755095654587\n",
      "Class 16 : 0.766550522113902\n",
      "Class 17 : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1081/2160 [26:06<9:40:24, 32.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved!\n",
      "*************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 2159/2160 [50:25<00:01,  1.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.8218737598922518\n",
      "Train Accuracy : 54.76190476190476\n",
      "< VALIDATION >\n",
      "*************************************************************************\n",
      "Validation Loss : 0.8697002685732311\n",
      "-------------------------------------------------------------------------\n",
      "Total Accuracy\n",
      "75.6878306878307 %\n",
      "-------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "519 6   1   17  7   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "17  155 88  0   44  10  0   1   0   0   0   0   0   0   0   0   0   0   \n",
      "0   42  125 0   7   6   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "13  0   0   702 5   8   0   0   0   0   0   0   0   0   0   0   1   1   \n",
      "0   0   0   41  365 264 0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "0   0   0   0   91  161 0   1   0   0   2   0   0   0   0   0   0   0   \n",
      "3   0   0   0   0   0   99  2   0   5   0   0   1   0   0   0   0   0   \n",
      "0   0   0   0   0   0   3   51  2   0   7   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   27  7   0   2   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   3   0   0   139 2   1   0   0   0   1   0   0   \n",
      "0   0   0   0   2   4   0   1   0   5   106 16  0   0   0   0   0   0   \n",
      "0   0   0   0   1   1   0   0   0   0   40  9   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   99  6   0   5   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   3   52  7   0   1   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   19  17  0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   2   1   0   141 1   1   \n",
      "0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   11  94  27  \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   30  20  \n",
      "-------------------------------------------------------------------------\n",
      "Validation F1 score : 0.6820227981126391\n",
      "Class 0 : 0.94192377478368\n",
      "Class 1 : 0.5984555982245345\n",
      "Class 2 : 0.6345177661753717\n",
      "Class 3 : 0.9422818790681502\n",
      "Class 4 : 0.61190276603321\n",
      "Class 5 : 0.45416078971673884\n",
      "Class 6 : 0.9209302317014603\n",
      "Class 7 : 0.6986301360292738\n",
      "Class 8 : 0.311111109728395\n",
      "Class 9 : 0.9423728807170354\n",
      "Class 10 : 0.723549487560717\n",
      "Class 11 : 0.23376623315904876\n",
      "Class 12 : 0.9209302317014603\n",
      "Class 13 : 0.7272727262555626\n",
      "Class 14 : 0.5666666647777777\n",
      "Class 15 : 0.9276315783370845\n",
      "Class 16 : 0.7203065128580027\n",
      "Class 17 : 0.39999999919999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2160/2160 [52:10<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved!\n",
      "*************************************************************************\n",
      "\n",
      "Epoch     2: adjusting learning rate of group 0 to 2.2625e-04.\n",
      "Epoch : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 1080/2160 [24:22<24:23,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.8081742870267291\n",
      "Train Accuracy : 58.22650984538126\n",
      "< VALIDATION >\n",
      "*************************************************************************\n",
      "Validation Loss : 0.8672033319870631\n",
      "-------------------------------------------------------------------------\n",
      "Total Accuracy\n",
      "77.01058201058201 %\n",
      "-------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "537 7   0   5   1   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "13  254 45  0   1   2   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "1   64  113 0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "20  2   0   669 35  4   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "1   14  0   17  234 404 0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "0   11  0   0   9   235 0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "2   0   0   0   0   0   104 3   0   1   0   0   0   0   0   0   0   0   \n",
      "0   1   0   0   0   1   3   44  12  0   2   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   11  23  0   2   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   4   1   0   137 3   0   0   0   0   1   0   0   \n",
      "0   0   0   0   0   5   0   2   0   4   94  29  0   0   0   0   0   0   \n",
      "0   0   0   0   0   4   0   3   0   0   18  26  0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   108 1   0   1   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   3   50  10  0   0   0   \n",
      "0   0   5   0   0   0   0   0   1   0   0   0   0   9   21  0   0   0   \n",
      "0   1   0   0   0   0   0   0   0   0   0   0   2   0   0   142 1   0   \n",
      "0   0   0   0   0   2   0   0   0   0   0   0   0   1   1   10  97  23  \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   26  23  \n",
      "-------------------------------------------------------------------------\n",
      "Validation F1 score : 0.7407195268546405\n",
      "Class 0 : 0.9555160140648549\n",
      "Class 1 : 0.7593423017161905\n",
      "Class 2 : 0.6588921278956897\n",
      "Class 3 : 0.9415904291426332\n",
      "Class 4 : 0.4926315788436565\n",
      "Class 5 : 0.5142231946358374\n",
      "Class 6 : 0.9411764697364919\n",
      "Class 7 : 0.6929133847355695\n",
      "Class 8 : 0.6388888871141976\n",
      "Class 9 : 0.9513888882282021\n",
      "Class 10 : 0.7430830033651518\n",
      "Class 11 : 0.49056603681025274\n",
      "Class 12 : 0.9686098646021436\n",
      "Class 13 : 0.7936507923910305\n",
      "Class 14 : 0.6176470570069205\n",
      "Class 15 : 0.9466666660355555\n",
      "Class 16 : 0.7519379839132263\n",
      "Class 17 : 0.47422680314592414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1081/2160 [26:06<9:40:53, 32.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved!\n",
      "*************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 2159/2160 [50:26<00:01,  1.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.8044551428269457\n",
      "Train Accuracy : 60.05291005291005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2160/2160 [52:10<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< VALIDATION >\n",
      "*************************************************************************\n",
      "Validation Loss : 0.873173654741711\n",
      "-------------------------------------------------------------------------\n",
      "Total Accuracy\n",
      "77.14285714285715 %\n",
      "-------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "515 15  3   11  1   0   4   1   0   0   0   0   0   0   0   0   0   0   \n",
      "15  208 72  0   17  2   1   0   0   0   0   0   0   0   0   0   0   0   \n",
      "0   50  129 0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   \n",
      "15  1   0   709 2   0   1   0   0   2   0   0   0   0   0   0   0   0   \n",
      "1   25  9   39  456 138 0   0   0   1   1   0   0   0   0   0   0   0   \n",
      "1   13  8   0   109 124 0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "2   0   0   0   0   0   90  2   0   16  0   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   1   5   44  11  1   1   0   0   0   0   0   0   0   \n",
      "0   0   1   0   0   0   0   10  24  0   1   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   2   0   0   142 0   0   0   0   0   2   0   0   \n",
      "0   0   1   0   2   3   0   22  0   13  76  17  0   0   0   0   0   0   \n",
      "0   0   0   0   1   0   0   8   3   0   17  21  0   0   0   0   0   1   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   109 0   0   1   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   6   51  6   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   13  23  0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   4   0   0   141 0   1   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   34  3   11  20  66  \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   13  1   0   3   34  \n",
      "-------------------------------------------------------------------------\n",
      "Validation F1 score : 0.6845858244029035\n",
      "Class 0 : 0.937215650420889\n",
      "Class 1 : 0.6634768737915544\n",
      "Class 2 : 0.6401985108485367\n",
      "Class 3 : 0.9523169911413947\n",
      "Class 4 : 0.7249602542567631\n",
      "Class 5 : 0.4741873803157984\n",
      "Class 6 : 0.8450704217417179\n",
      "Class 7 : 0.5866666658844444\n",
      "Class 8 : 0.6399999982933332\n",
      "Class 9 : 0.8847352019409749\n",
      "Class 10 : 0.6608695646427222\n",
      "Class 11 : 0.4719101112990784\n",
      "Class 12 : 0.9519650646707729\n",
      "Class 13 : 0.5862068958779232\n",
      "Class 14 : 0.6666666647342995\n",
      "Class 15 : 0.9368770757894505\n",
      "Class 16 : 0.25477706973913744\n",
      "Class 17 : 0.4444444438634714\n",
      "model saved!\n",
      "*************************************************************************\n",
      "\n",
      "Epoch     3: adjusting learning rate of group 0 to 1.5250e-04.\n",
      "Epoch : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 1080/2160 [24:22<24:24,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.7988096412192\n",
      "Train Accuracy : 61.411391568653364\n",
      "< VALIDATION >\n",
      "*************************************************************************\n",
      "Validation Loss : 0.8614923114026034\n",
      "-------------------------------------------------------------------------\n",
      "Total Accuracy\n",
      "81.42857142857143 %\n",
      "-------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "524 9   2   13  2   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "13  187 48  0   52  13  0   0   0   0   2   0   0   0   0   0   0   0   \n",
      "0   55  120 0   0   5   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "12  0   0   700 17  1   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "0   0   1   20  560 87  0   0   0   0   2   0   0   0   0   0   0   0   \n",
      "0   0   0   0   150 100 0   0   0   0   5   0   0   0   0   0   0   0   \n",
      "2   0   0   0   0   0   105 1   0   1   0   0   1   0   0   0   0   0   \n",
      "0   0   0   0   0   0   3   38  8   0   13  1   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   9   24  0   3   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   4   0   0   137 4   0   0   0   0   1   0   0   \n",
      "0   0   0   0   0   2   0   0   0   2   123 7   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   35  16  0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   109 0   0   1   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   4   37  10  0   10  2   \n",
      "0   0   4   0   0   0   0   0   0   0   0   0   0   8   22  0   2   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   140 3   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   115 16  \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   30  21  \n",
      "-------------------------------------------------------------------------\n",
      "Validation F1 score : 0.7467129133598742\n",
      "Class 0 : 0.9518619435146483\n",
      "Class 1 : 0.6607773849255203\n",
      "Class 2 : 0.6760563376472923\n",
      "Class 3 : 0.9569377989122437\n",
      "Class 4 : 0.771881460954944\n",
      "Class 5 : 0.4319654425779847\n",
      "Class 6 : 0.9459459450937423\n",
      "Class 7 : 0.6846846834510184\n",
      "Class 8 : 0.7058823508650519\n",
      "Class 9 : 0.9580419573719987\n",
      "Class 10 : 0.766355139709436\n",
      "Class 11 : 0.4266666655288888\n",
      "Class 12 : 0.9603524220613635\n",
      "Class 13 : 0.6851851839163238\n",
      "Class 14 : 0.6470588216262976\n",
      "Class 15 : 0.9621993120534714\n",
      "Class 16 : 0.7823129246378824\n",
      "Class 17 : 0.46666666562962966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1081/2160 [26:06<9:40:55, 32.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved!\n",
      "*************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1565/2160 [37:01<13:26,  1.35s/it]  IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 50%|█████     | 1080/2160 [24:20<24:26,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.7968974508806912\n",
      "Train Accuracy : 61.91357208933527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1081/2160 [26:03<9:37:02, 32.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< VALIDATION >\n",
      "*************************************************************************\n",
      "Validation Loss : 0.8620907920378226\n",
      "-------------------------------------------------------------------------\n",
      "Total Accuracy\n",
      "82.01058201058201 %\n",
      "-------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "528 15  0   6   0   0   1   0   0   0   0   0   0   0   0   0   0   0   \n",
      "15  262 15  0   23  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "0   99  74  0   1   5   0   1   0   0   0   0   0   0   0   0   0   0   \n",
      "35  1   0   644 38  1   0   0   0   11  0   0   0   0   0   0   0   0   \n",
      "2   4   1   2   618 43  0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "0   1   0   0   165 89  0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "2   0   0   0   0   0   102 4   0   0   2   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   2   51  2   0   8   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   24  11  0   1   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   3   0   0   132 10  0   0   0   0   1   0   0   \n",
      "0   0   0   0   0   1   0   2   0   1   123 7   0   0   0   0   0   0   \n",
      "0   0   0   0   1   1   0   0   0   0   28  21  0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   101 7   0   2   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   1   52  2   0   8   0   \n",
      "0   0   1   0   0   0   0   0   0   0   0   0   0   21  14  0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   3   1   0   134 7   1   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   126 6   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   33  18  \n",
      "-------------------------------------------------------------------------\n",
      "Validation F1 score : 0.7329769703320447\n",
      "Class 0 : 0.9328621906479042\n",
      "Class 1 : 0.7517934000712214\n",
      "Class 2 : 0.546125460851568\n",
      "Class 3 : 0.9319826337290908\n",
      "Class 4 : 0.815303429971596\n",
      "Class 5 : 0.45063291116423654\n",
      "Class 6 : 0.9357798156552479\n",
      "Class 7 : 0.7034482748917955\n",
      "Class 8 : 0.4489795900041649\n",
      "Class 9 : 0.9103448269583828\n",
      "Class 10 : 0.803921568102012\n",
      "Class 11 : 0.531645568274315\n",
      "Class 12 : 0.9395348828469443\n",
      "Class 13 : 0.7172413783210464\n",
      "Class 14 : 0.5384615363905325\n",
      "Class 15 : 0.9436619711664354\n",
      "Class 16 : 0.8181818176505313\n",
      "Class 17 : 0.4736842092797784\n",
      "model saved!\n",
      "*************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 2159/2160 [50:20<00:01,  1.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.7952612224552367\n",
      "Train Accuracy : 62.95634920634921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2160/2160 [52:04<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< VALIDATION >\n",
      "*************************************************************************\n",
      "Validation Loss : 0.8684323972022092\n",
      "-------------------------------------------------------------------------\n",
      "Total Accuracy\n",
      "77.5132275132275 %\n",
      "-------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "488 42  5   6   8   0   1   0   0   0   0   0   0   0   0   0   0   0   \n",
      "11  224 56  0   24  0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "0   68  112 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "15  4   2   577 122 3   0   0   1   1   3   0   0   0   0   0   2   0   \n",
      "0   4   5   0   570 90  1   0   0   0   0   0   0   0   0   0   0   0   \n",
      "0   0   0   0   137 118 0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "2   0   0   0   0   0   99  7   0   0   2   0   0   0   0   0   0   0   \n",
      "0   0   0   0   1   0   3   50  7   0   2   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   16  20  0   0   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   3   0   0   112 29  1   0   0   0   1   0   0   \n",
      "0   0   0   0   0   2   0   2   0   0   111 19  0   0   0   0   0   0   \n",
      "0   0   0   0   1   2   0   0   0   0   23  25  0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   105 2   0   1   2   0   \n",
      "0   0   1   0   0   0   0   0   0   0   1   0   5   45  9   0   2   0   \n",
      "0   0   2   0   0   0   0   0   0   0   0   0   0   13  21  0   0   0   \n",
      "0   0   1   0   0   0   0   0   0   0   0   0   4   0   0   124 17  0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   3   1   1   101 28  \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   23  28  \n",
      "-------------------------------------------------------------------------\n",
      "Validation F1 score : 0.7301368986823589\n",
      "Class 0 : 0.9155722324736264\n",
      "Class 1 : 0.6818873666112976\n",
      "Class 2 : 0.6153846150464919\n",
      "Class 3 : 0.8789032748090018\n",
      "Class 4 : 0.743639921625096\n",
      "Class 5 : 0.5021276593607967\n",
      "Class 6 : 0.9124423954724034\n",
      "Class 7 : 0.7246376801092207\n",
      "Class 8 : 0.6249999980468751\n",
      "Class 9 : 0.8648648641970156\n",
      "Class 10 : 0.7278688519817254\n",
      "Class 11 : 0.5208333322482639\n",
      "Class 12 : 0.9374999991629464\n",
      "Class 13 : 0.7142857131519275\n",
      "Class 14 : 0.6268656697705502\n",
      "Class 15 : 0.9084249077593958\n",
      "Class 16 : 0.7188612094527679\n",
      "Class 17 : 0.523364485003057\n",
      "model saved!\n",
      "*************************************************************************\n",
      "\n",
      "Epoch     8: adjusting learning rate of group 0 to 2.2625e-04.\n",
      "Epoch : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 1034/2160 [23:16<25:24,  1.35s/it]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 50%|█████     | 1080/2160 [24:19<24:29,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.7842293968915278\n",
      "Train Accuracy : 66.56534954407294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1081/2160 [26:03<9:36:37, 32.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< VALIDATION >\n",
      "*************************************************************************\n",
      "Validation Loss : 0.8610326429208119\n",
      "-------------------------------------------------------------------------\n",
      "Total Accuracy\n",
      "81.58730158730158 %\n",
      "-------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "520 17  0   7   3   3   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "13  245 54  0   2   0   0   1   0   0   0   0   0   0   0   0   0   0   \n",
      "0   52  128 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "10  1   2   680 22  14  0   0   0   0   0   0   0   0   1   0   0   0   \n",
      "0   10  2   16  449 193 0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "0   6   0   0   84  165 0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "2   0   0   0   0   0   104 3   0   1   0   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   3   47  9   0   4   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   12  23  0   1   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   2   0   0   139 2   1   0   0   0   2   0   0   \n",
      "0   0   0   0   0   2   0   4   0   4   110 14  0   0   0   0   0   0   \n",
      "0   0   0   0   0   1   0   2   0   0   24  24  0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   103 2   0   5   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   2   57  4   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   15  21  0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   2   0   1   140 2   1   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   8   1   5   109 11  \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   3   0   0   28  20  \n",
      "-------------------------------------------------------------------------\n",
      "Validation F1 score : 0.7685784310305693\n",
      "Class 0 : 0.9497716893242427\n",
      "Class 1 : 0.7585139316537108\n",
      "Class 2 : 0.6994535515303533\n",
      "Class 3 : 0.949057920314158\n",
      "Class 4 : 0.7300813006942958\n",
      "Class 5 : 0.5213270140532931\n",
      "Class 6 : 0.9497716886303456\n",
      "Class 7 : 0.7121212110422407\n",
      "Class 8 : 0.6764705862456748\n",
      "Class 9 : 0.9586206889940547\n",
      "Class 10 : 0.7999999994181819\n",
      "Class 11 : 0.5333333321481482\n",
      "Class 12 : 0.9493087548854299\n",
      "Class 13 : 0.7702702692293645\n",
      "Class 14 : 0.6562499979492188\n",
      "Class 15 : 0.9395973148056393\n",
      "Class 16 : 0.7985347979497913\n",
      "Class 17 : 0.48192770968210186\n",
      "model saved!\n",
      "*************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 2159/2160 [50:20<00:01,  1.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss : 0.7847631104566433\n",
      "Train Accuracy : 66.09126984126983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2160/2160 [52:03<00:00, 32.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< VALIDATION >\n",
      "*************************************************************************\n",
      "Validation Loss : 0.860505426813055\n",
      "-------------------------------------------------------------------------\n",
      "Total Accuracy\n",
      "82.51322751322752 %\n",
      "-------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "532 11  0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "18  280 8   0   8   0   0   1   0   0   0   0   0   0   0   0   0   0   \n",
      "0   96  84  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "24  1   0   677 27  0   0   0   0   1   0   0   0   0   0   0   0   0   \n",
      "2   1   0   15  531 121 0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "0   1   0   0   135 119 0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "2   0   0   0   0   0   106 1   0   1   0   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   4   55  2   0   2   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   19  17  0   0   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   3   0   0   139 4   0   0   0   0   0   0   0   \n",
      "0   0   0   0   0   3   0   2   0   2   117 10  0   0   0   0   0   0   \n",
      "0   0   0   0   0   2   0   0   0   0   30  19  0   0   0   0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   104 5   0   1   0   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   2   59  0   0   2   0   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   19  17  0   0   0   \n",
      "0   0   0   0   0   0   0   0   0   1   0   0   2   1   0   130 11  1   \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   2   109 22  \n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   27  24  \n",
      "-------------------------------------------------------------------------\n",
      "Validation F1 score : 0.7631258483720837\n",
      "Class 0 : 0.9432624111802727\n",
      "Class 1 : 0.794326240909411\n",
      "Class 2 : 0.6176470583693772\n",
      "Class 3 : 0.9475157451438047\n",
      "Class 4 : 0.7746170677206977\n",
      "Class 5 : 0.47599999980960006\n",
      "Class 6 : 0.9506726448872892\n",
      "Class 7 : 0.780141842865047\n",
      "Class 8 : 0.6181818159338843\n",
      "Class 9 : 0.9586206889940547\n",
      "Class 10 : 0.8153310098847869\n",
      "Class 11 : 0.47499999881250005\n",
      "Class 12 : 0.9541284394916254\n",
      "Class 13 : 0.7972972962198686\n",
      "Class 14 : 0.6415094315414738\n",
      "Class 15 : 0.9318996409090325\n",
      "Class 16 : 0.7703180206570189\n",
      "Class 17 : 0.4897959173677634\n",
      "model saved!\n",
      "*************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2160/2160 [52:04<00:00,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    10: adjusting learning rate of group 0 to 7.8750e-05.\n",
      "Epoch : 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███▋      | 793/2160 [17:53<30:51,  1.35s/it]"
     ]
    }
   ],
   "source": [
    "folder = '/opt/ml/weights/{}'.format(config['model'])\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(\"Epoch :\", epoch + 1)\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    total = 0\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    \n",
    "    total_it = int(len(dataset_train)/train_dataloader.batch_size)\n",
    "    prog_bar = tqdm(enumerate(train_dataloader), total=total_it)\n",
    "    for i, (images, labels) in prog_bar:\n",
    "        \n",
    "        counter += 1\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        if \"cutmix\" in config['augmentation']:\n",
    "            if config['beta'] > 0 and np.random.random() > 0.5: # cutmix가 실행될 경우     \n",
    "                    lam = np.random.beta(config['beta'], config['beta'])\n",
    "                    rand_index = torch.randperm(images.size()[0]).to(device)\n",
    "                    target_a = labels # 원본 이미지 label\n",
    "                    target_b = labels[rand_index] # 패치 이미지 label       \n",
    "                    bbx1, bby1, bbx2, bby2 = rand_bbox(images.size(), lam)\n",
    "                    images[:, :, bbx1:bbx2, bby1:bby2] = images[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.size()[-1] * images.size()[-2]))\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, target_a) * lam + criterion(outputs, target_b) * (1. - lam) # 패치 이미지와 원본 이미지의 비율에 맞게 loss를 계산을 해주는 부분\n",
    "\n",
    "            else: # cutmix가 실행되지 않았을 경우\n",
    "                outputs = model(images) \n",
    "                loss = criterion(outputs, labels)\n",
    "        \n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            counter += 1\n",
    "            \n",
    "           \n",
    "        _, preds= torch.max(outputs, 1) \n",
    "#         _, preds = torch.max(outputs.data, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step() \n",
    "        train_running_loss += loss.item()\n",
    "        train_running_correct += (preds == labels).sum().item()\n",
    "        \n",
    "        \n",
    "        del images\n",
    "        del labels\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if i == total_it//2 or i == total_it-1:\n",
    "            train_loss = train_running_loss / counter\n",
    "            train_accuracy = 100. * train_running_correct / total\n",
    "            \n",
    "            print(\"Train Loss :\", train_loss)\n",
    "            print(\"Train Accuracy :\", train_accuracy)\n",
    "            wandb.log({\"Train Loss\" : train_loss,\n",
    "                      \"Train Accuracy\" : train_accuracy})\n",
    "            try:\n",
    "                check()\n",
    "            except:\n",
    "                pass\n",
    "    scheduler.step()\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d8c054-35f0-460b-a26c-8d4bcf76981f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ffe99-f672-4c06-a95f-bc9e6514776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/opt/ml/weights/{}/{:.4f}.pt'.format(config['model'], model.best_f1))), model.best_f1\n",
    "\n",
    "# Q = \"0.7737\"\n",
    "# model.load_state_dict(torch.load('/opt/ml/weights/{}/{}.pt'.format(config['model'], Q)))\n",
    "# model.best_f1 = Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d88042-fc04-4f8f-a577-18d5a62f5b8a",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9301c-33a1-435c-8534-9d5ffb2f4d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'new_images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "dataset = TestDataset(image_paths, transform=test_transform)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    "    num_workers=3\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "\n",
    "prog_bar = tqdm(enumerate(loader), total=int(len(dataset)/loader.batch_size))\n",
    "for i, images in prog_bar:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, '{}_{}.csv'.format(config['model'], model.best_f1)), index=False)\n",
    "print('test inference is done!', config['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad864cf0-4577-4099-bf31-144020aea524",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'new_images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "\n",
    "idx = 200\n",
    "image = cv2.imread(image_paths[idx])\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "\n",
    "image = test_transform(image=image)['image'].to(device)\n",
    "image = image.unsqueeze(0)\n",
    "pred = model(image)\n",
    "label = np.argmax(pred.detach().cpu().numpy())\n",
    "\n",
    "masklabel = {0: \"Mask\", 1: \"Incorrect\", 2: \"Normal\"}\n",
    "genderlabel = {0: \"Male\", 1: \"Female\"}\n",
    "agelabel = {0: \"~ 30\", 1: \"30 ~ 60\", 2: \"60 ~\"}\n",
    "\n",
    "feature_to_label = {}\n",
    "features = [(m, g, a) for m in ['Mask', 'Incorrect', 'Normal'] for g in ['Male', 'Female'] for a in [\"~ 30\", \"30 ~ 60\", \"60 ~\"]]\n",
    "for i, (m, g, a) in enumerate(features):\n",
    "    feature_to_label[(m, g, a)] = i\n",
    "\n",
    "label_to_feature = { feature_to_label[k]:k for k in feature_to_label}\n",
    "m, g, a = label_to_feature[label]\n",
    "print(m)\n",
    "print(g)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00159628-cbed-4f73-8c72-6bbecdfc4f01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
