{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myoukind\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">efficientnet-b6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/youkind/MaskClassification\" target=\"_blank\">https://wandb.ai/youkind/MaskClassification</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/youkind/MaskClassification/runs/30xt1bho\" target=\"_blank\">https://wandb.ai/youkind/MaskClassification/runs/30xt1bho</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/git/JH/wandb/run-20210825_082757-30xt1bho</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(30xt1bho)</h1><iframe src=\"https://wandb.ai/youkind/MaskClassification/runs/30xt1bho\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f70ef40efa0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "\n",
    "config={\n",
    "    \"lr\": 2e-4,\n",
    "    \"dropout\": 0.5,\n",
    "    \"architecture\": \"efficientnet-b6 + 3way\",\n",
    "    \"dataset\": \"vanilla + mask\",\n",
    "    \"augmentation\" : \"None\",\n",
    "    \"age_weightedloss\" : [1.0, 1.2, 3.],\n",
    "    \"gender_weightedloss\" : [1.4, 1.0],\n",
    "    \"gamma\" : 0.85,\n",
    "    \"batch_size\" : 64,\n",
    "    \"epochs\" : 15,\n",
    "    'model' : 'efficientnet-b6'\n",
    "}\n",
    "\n",
    "wandb.init(project=\"MaskClassification\", name=config['model'], config=config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb8f33ff-a325-4a5e-95f9-27f0a0cb131c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA GPU available : True\n",
      "1 GPU(s) is(are) allocated\n"
     ]
    }
   ],
   "source": [
    "print('CUDA GPU available : {}'.format(torch.cuda.is_available()))\n",
    "try:\n",
    "    print('{} GPU(s) is(are) allocated'.format(torch.cuda.device_count()))\n",
    "except:\n",
    "    print('GPUs are not allocated. Current runtime is on CPU.')\n",
    "device = torch.device(\"cuda\")\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "built-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "train_dir = '/opt/ml/input/data/train'\n",
    "\n",
    "labels_to_class = {}\n",
    "it = [(m, g, a) for m in [0,1,2] for g in [0, 1] for a in [0, 1, 2]]\n",
    "for i, (m, g, a) in enumerate(it):\n",
    "    labels_to_class[(m, g, a)] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-channels",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extensive-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, train_dir, is_Train=True, transform=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        csv_path = os.path.join(train_dir, 'train.csv')\n",
    "        csv = pd.read_csv(csv_path)\n",
    "        self.image_dir = os.path.join(train_dir, 'images')\n",
    "        self.transform = transform\n",
    "        self.image_path = []\n",
    "        path = csv['path']\n",
    "        \n",
    "        for p in path:\n",
    "            images = [os.path.join(*[self.image_dir, p, image]) for image in os.listdir(os.path.join(self.image_dir, p)) if not image[:1] == '.']\n",
    "            for image in images:\n",
    "                self.image_path.append(image)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_path[idx]\n",
    "        image = cv2.imread(image_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        features = image_name.split('/')[-2:]\n",
    "        \n",
    "        masktoint = {'m' : 0, 'i' : 1, 'n' : 2}\n",
    "        gendertoint = {'male' : 0, 'female' : 1}\n",
    "        \n",
    "        mask = masktoint[features[1][0]]\n",
    "        age = int(features[0].split('_')[-1])\n",
    "        gender = gendertoint[features[0].split('_')[1]]\n",
    "        \n",
    "        if age >= 58: # 원래 60\n",
    "            age = 2\n",
    "        elif age >= 30: # 원래 30\n",
    "            age = 1\n",
    "        else:\n",
    "            age = 0        \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "        \n",
    "        return image, (mask, gender, age)\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = cv2.imread(self.img_paths[index])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596e6a97-3fe9-458a-9455-ace9d7a99877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "tfms = A.Compose([\n",
    "        A.augmentations.crops.transforms.CenterCrop(400, 360, p=1.0),\n",
    "        A.augmentations.geometric.resize.Resize(224, 224, interpolation=1, p=1),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.6),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, p=0.6),\n",
    "        A.GaussNoise(p=0.5),\n",
    "        A.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
    "        A.pytorch.transforms.ToTensorV2(),\n",
    "    ])\n",
    "tfms_test = A.Compose([\n",
    "        A.augmentations.crops.transforms.CenterCrop(400, 360, p=1.0),\n",
    "        A.augmentations.geometric.resize.Resize(224, 224, interpolation=1, p=1),\n",
    "        A.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
    "        A.pytorch.transforms.ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "person_idx = list(range(2700))\n",
    "np.random.shuffle(person_idx)\n",
    "n_val_person = int(2700 * 0.2)\n",
    "val_person_idx = person_idx[:n_val_person]\n",
    "\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "for i in range(2700*15):\n",
    "    if i // 15 not in val_person_idx:\n",
    "        train_indices.append(i)\n",
    "    else:\n",
    "        val_indices.append(i)\n",
    "        \n",
    "dataset = TrainDataset(train_dir, transform=tfms)\n",
    "# train_dataset, val_dataset = random_split(dataset, [int(len(dataset)*0.8),int(len(dataset)*0.2)])\n",
    "# print(len(dataset))\n",
    "# plt.imshow(np.array(train[1][0].permute(1,2,0)))\n",
    "train_loader = DataLoader(dataset, batch_size=config['batch_size'], pin_memory=True, num_workers=4, sampler=train_indices)\n",
    "val_loader   = DataLoader(dataset, num_workers=4, batch_size=config['batch_size'], pin_memory=True, sampler=val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aeacde3-f357-4129-a73a-2000a48d315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.array(train_dataset[312][0]['image'].permute(1,2,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21006028-25ad-4414-8bae-730a3bcc33e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3174fa2-72d4-475b-bffd-ad23c4669521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b6\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "class Way3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.convnet = timm.create_model(config['model'], pretrained=True, num_classes=512)\n",
    "        self.convnet = EfficientNet.from_pretrained(config['model'], num_classes=512).to(device)\n",
    "        self.mask = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=config['dropout'], inplace=False),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=config['dropout'], inplace=False),\n",
    "            nn.Linear(128, 3),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.gender = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=config['dropout'], inplace=False),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=config['dropout'], inplace=False),\n",
    "            nn.Linear(128, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.age = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=config['dropout'], inplace=False),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=config['dropout'], inplace=False),\n",
    "            nn.Linear(128, 3),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.best_f1 = 0\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.convnet(x)\n",
    "        mask = self.mask(features)\n",
    "        gender = self.gender(features)\n",
    "        age = self.age(features)\n",
    "        \n",
    "        return mask, gender, age\n",
    "    \n",
    "model = Way3().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4b1aa9f-2fa1-417f-9e3e-7f160fef7d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim \n",
    "\n",
    "gender_weight = torch.tensor(config[\"gender_weightedloss\"])\n",
    "age_weight = torch.tensor(config[\"age_weightedloss\"])\n",
    "                             \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "gender_criterion = nn.CrossEntropyLoss(weight=gender_weight).to(device)\n",
    "age_criterion = nn.CrossEntropyLoss(weight=age_weight).to(device)\n",
    "# b_criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = FocalLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=config['gamma'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84d269a9-9771-4364-a927-b06cf5ac86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def check(loader, length, model, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    counter = 0\n",
    "    y_true = []\n",
    "    y_predicted = []\n",
    "\n",
    "    m_acc = []\n",
    "    g_acc = []\n",
    "    a_acc = []\n",
    "    with torch.no_grad():\n",
    "        for (inputs, (m, g, a)) in val_loader:\n",
    "            counter += 1\n",
    "            \n",
    "            for mask, gender, age in zip(m, g, a):\n",
    "                answer = labels_to_class[(mask.item(), gender.item(), age.item())]\n",
    "                y_true.append(answer)\n",
    "            \n",
    "            inputs = inputs.to(device=device)\n",
    "            m = m.to(device)\n",
    "            g = g.to(device)\n",
    "            a = a.to(device)\n",
    "\n",
    "            m_pred, g_pred, a_pred = model(inputs)\n",
    "    \n",
    "            m_loss = criterion(m_pred, m)\n",
    "            g_loss = gender_criterion(g_pred, g)\n",
    "            a_loss = age_criterion(a_pred, a) # data imbalance\n",
    "            \n",
    "            loss = (g_loss+a_loss+m_loss)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            m_argmax = m_pred.detach().cpu().numpy().argmax(1)\n",
    "            g_argmax = g_pred.detach().cpu().numpy().argmax(1)\n",
    "            a_argmax = a_pred.detach().cpu().numpy().argmax(1)\n",
    "\n",
    "            m_acc.append(accuracy_score(m_argmax, m.detach().cpu().numpy()))\n",
    "            g_acc.append(accuracy_score(g_argmax, g.detach().cpu().numpy()))\n",
    "            a_acc.append(accuracy_score(a_argmax, a.detach().cpu().numpy()))\n",
    "\n",
    "            for mask, gender, age in zip(m_argmax, g_argmax, a_argmax):\n",
    "                predicted = labels_to_class[(mask.item(), gender.item(), age.item())]\n",
    "                y_predicted.append(predicted)\n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_predicted)\n",
    "    F1 = []\n",
    "    for c in range(18):\n",
    "        precision = cm[c][c] / np.sum(cm, axis=0)[c]\n",
    "        recall = cm[c][c] / np.sum(cm, axis=1)[c]\n",
    "        F1.append(2 * precision * recall / (precision + recall))\n",
    "    macro_F1 = np.mean(F1)\n",
    "\n",
    "    s = 0\n",
    "    for c in range(18):\n",
    "        s += cm[c][c]\n",
    "        \n",
    "    print(\"< VALIDATION >\")\n",
    "    print(\"*\"*73)\n",
    "    print(\"Validation Loss :\", val_loss/counter)\n",
    "    print(\"-\"*73)\n",
    "    print(\"Total Accuracy\")\n",
    "    print(s / length * 100, \"%\")\n",
    "    print(\"-\"*73)\n",
    "    print(\"Class Accuracy\")\n",
    "    print(\"Mask   :\", np.mean(m_acc)*100, \"%\")\n",
    "    print(\"Gender :\", np.mean(g_acc)*100, \"%\")\n",
    "    print(\"Age    :\", np.mean(a_acc)*100, \"%\")\n",
    "    print(\"-\"*73)\n",
    "    print(\"Confusion Matrix\")\n",
    "    for row in cm:\n",
    "        print(row)\n",
    "    print(\"-\"*73)\n",
    "    print(\"Validation F1 score :\" , macro_F1)\n",
    "    if model.best_f1 < macro_F1:\n",
    "        model.best_f1 = macro_F1\n",
    "        torch.save(model.state_dict(), '/opt/ml/weights/3way/{}/{:.4f}.pt'.format(config['model'], model.best_f1))\n",
    "        print(\"model saved!\")\n",
    "    print(\"*\"*73)\n",
    "    print()\n",
    "    wandb.log({\n",
    "        \"Validation Loss\" : val_loss/counter, \n",
    "        \"Validation Total Accuracy\" : s / length *100, \n",
    "        \"Validation F1\" : macro_F1,\n",
    "        \"Mask Accuracy\" : np.mean(m_acc)*100,\n",
    "        \"Gender Accuracy\" : np.mean(g_acc)*100,\n",
    "        \"Age Accuracy\" : np.mean(a_acc)*100,\n",
    "    })\n",
    "        \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c14aa58-ddfa-4ca7-a5d9-3311991b781a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'exist_ok' is an invalid keyword argument for mkdir()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-31d0bee07c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/opt/ml/weights/3way/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_running_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'exist_ok' is an invalid keyword argument for mkdir()"
     ]
    }
   ],
   "source": [
    "\n",
    "folder = '/opt/ml/weights/3way/{}'.format(config['model']\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    print(\"Epoch :\", epoch + 1)\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    counter = 0\n",
    "    total = 0\n",
    "    total_it = int(len(train_dataset)/train_loader.batch_size)\n",
    "    prog_bar = tqdm(enumerate(train_loader), total=total_it)\n",
    "    for i, (inputs, (m, g, a)) in prog_bar:\n",
    "        \n",
    "        counter += 1\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)\n",
    "        m_pred, g_pred, a_pred = model(inputs)\n",
    "        \n",
    "        \n",
    "        m = m.to(device)\n",
    "        g = g.to(device)\n",
    "        a = a.to(device)\n",
    "        total += m.size(0)\n",
    "        \n",
    "        \n",
    "        m_loss = criterion(m_pred, m)\n",
    "        g_loss = gender_criterion(g_pred, g)\n",
    "        a_loss = age_criterion(a_pred, a) # data imbalance\n",
    "        \n",
    "        \n",
    "        loss = (g_loss+a_loss+m_loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_running_loss += loss.item()\n",
    "        \n",
    "        if i == total_it//2 or i == total_it-1:\n",
    "            train_loss = train_running_loss / counter\n",
    "\n",
    "            print(\"Loss :\", train_loss)\n",
    "            wandb.log({\"Train Loss\" : train_loss})\n",
    "            \n",
    "            check(val_loader, len(val_dataset), model, device)\n",
    "    scheduler.step()\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "print(\"Finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-feelings",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf6622-e3d7-401a-84d8-82ba94f6e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/opt/ml/weights/3way/{}/{:.4f}.pt'.format(config['model'], model.best_f1)))\n",
    "# model.load_state_dict(torch.load('/opt/ml/weights/3way/{}/0.9841404744270768.pt'.format(config['model']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "image_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n",
    "dataset = TestDataset(image_paths, tfms_test)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=False,\n",
    "    batch_size=64,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "# device = torch.device('cuda')\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda:0\")\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "\n",
    "prog_bar = tqdm(enumerate(loader), total=int(len(dataset)/loader.batch_size))\n",
    "for i, images in prog_bar:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        m_pred, g_pred, a_pred = model(images)\n",
    "#         print(images.shape)\n",
    "#         print(m_pred.shape)\n",
    "        m_argmax = m_pred.detach().cpu().numpy().argmax(1)\n",
    "        g_argmax = g_pred.detach().cpu().numpy().argmax(1)\n",
    "        a_argmax = a_pred.detach().cpu().numpy().argmax(1)\n",
    "        \n",
    "        for mask, gender, age in zip(m_argmax, g_argmax, a_argmax):\n",
    "            predicted = labels_to_class[(mask.item(), gender.item(), age.item())]\n",
    "            all_predictions.append(predicted)\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01883cc5-1adf-4c19-ba4b-e53ce43575ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1020\n",
    "image = cv2.imread(image_paths[idx])\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "\n",
    "image = tfms_test(image=image)['image'].to(device)\n",
    "image = image.unsqueeze(0)\n",
    "m_pred, g_pred, a_pred = model(image)\n",
    "\n",
    "m_argmax = m_pred.detach().cpu().numpy().argmax(1)\n",
    "g_argmax = g_pred.detach().cpu().numpy().argmax(1)\n",
    "a_argmax = a_pred.detach().cpu().numpy().argmax(1)\n",
    "\n",
    "#\n",
    "masklabel = {0: \"Mask\", 1: \"Incorrect\", 2: \"Normal\"}\n",
    "genderlabel = {0: \"Male\", 1: \"Female\"}\n",
    "agelabel = {0: \"~ 30\", 1: \"30 ~ 60\", 2: \"60 ~\"}\n",
    "#\n",
    "print(masklabel[m_argmax[0]]+ \" :\", (m_pred[0][m_argmax].item())*100, '%')\n",
    "print(genderlabel[g_argmax[0]]+ \" :\", (g_pred[0][g_argmax].item())*100, '%')\n",
    "print(agelabel[a_argmax[0]]+ \" :\", (a_pred[0][a_argmax].item())*100, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614e887-7750-4c03-80a5-7a0a5b3fab38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
