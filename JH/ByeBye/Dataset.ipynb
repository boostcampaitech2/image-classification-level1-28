{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6c693b-8a00-4a77-8c85-10c212680012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/std.py:703: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from sklearn.metrics import f1_score\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b89bd7-404b-415a-8912-c190004cdfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is using!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device} is using!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae3374a-8f33-44ad-997a-e2bf45d07dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 4\n",
    "OUTPUT_CLASS = 18\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fcafbfa-4bf3-4524-910d-6815d9bc77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path, label, transform):\n",
    "        img_list = []\n",
    "        for p in tqdm(path):\n",
    "            img = cv2.imread(p)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_list.append(img)\n",
    "        \n",
    "        self.X = img_list\n",
    "        self.y = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        len_dataset = len(self.X)\n",
    "        return len_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X,y = self.X[idx], self.y[idx]\n",
    "        X = self.transform(image=X)['image']  # transforms를 사용하시는 분은 X = self.transform(X)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc4be2e3-e1bf-401d-a746-3e08a624a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, path, label, transform):\n",
    "        img_list = []\n",
    "        for p in tqdm(path):\n",
    "            img = cv2.imread(p)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_list.append(img)\n",
    "        \n",
    "        self.X = img_list\n",
    "        self.y = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        len_dataset = len(self.X)\n",
    "        return len_dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X,y = self.X[idx], self.y[idx]\n",
    "        X = self.transform(image=X)['image']  # transforms를 사용하시는 분은 X = self.transform(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76012de7-bb71-468b-b135-786439648026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation은 각자 방식대로\n",
    "\n",
    "train_transform = albumentations.Compose(\n",
    "  [\n",
    "      albumentations.Resize(600,600),\n",
    "#       albumentations.RandomRotation(15),\n",
    "#       albumentations.HorizontalFlip(p=0.3),\n",
    "      albumentations.OneOf([albumentations.ShiftScaleRotate(rotate_limit=15, p=0.5),\n",
    "                            albumentations.MotionBlur(p=0.5),\n",
    "                            albumentations.OpticalDistortion(p=0.5),\n",
    "                            albumentations.GaussNoise(p=0.5)], p=1),\n",
    "      albumentations.Normalize((0.548, 0.504, 0.479), (0.237, 0.247, 0.246)),\n",
    "      albumentations.pytorch.transforms.ToTensorV2(),\n",
    "      #       이미지 원본 사이즈는 384, 512   \n",
    "  ]\n",
    ")\n",
    "\n",
    "test_transform = albumentations.Compose(\n",
    "  [\n",
    "      albumentations.Resize(600,600),\n",
    "      albumentations.Normalize((0.548, 0.504, 0.479), (0.237, 0.247, 0.246)),\n",
    "      albumentations.pytorch.transforms.ToTensorV2()\n",
    "      #       이미지 원본 사이즈는 384, 512   \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "536915c8-e29b-4664-8b75-040ceead26a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15120/15120 [00:43<00:00, 344.74it/s]\n",
      "100%|██████████| 3780/3780 [00:10<00:00, 347.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# DF 읽어오기\n",
    "train_df = pd.read_csv('/opt/ml/input/train_df.csv')\n",
    "valid_df = pd.read_csv('/opt/ml/input/valid_df.csv')\n",
    "\n",
    "# Dataset 객체 생성\n",
    "dataset_train = MyDataset(path=train_df['full_path'].values,\n",
    "                          label=train_df['label'].values,\n",
    "                          transform=train_transform)\n",
    "\n",
    "dataset_valid = MyDataset(path=valid_df['full_path'].values,\n",
    "                          label=valid_df['label'].values,\n",
    "                          transform=test_transform)\n",
    "\n",
    "# Loader 올리기\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_dataloader = DataLoader(dataset_valid, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a251fd-fd65-4f39-9d9d-453e71e33dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
